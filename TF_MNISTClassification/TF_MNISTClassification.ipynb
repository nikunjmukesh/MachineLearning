{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "MNIST = input_data.read_data_sets('MNIST_data', one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.1108551025390625\n",
      "loss: 0.3502383828163147\n",
      "loss: 0.34167325496673584\n",
      "loss: 0.2512718439102173\n",
      "loss: 0.3359946012496948\n",
      "test acc: 0.9200999736785889\n"
     ]
    }
   ],
   "source": [
    "lr = 0.1 # learning rate \n",
    "batch_size = 128 # the number of example we will consider per iterations\n",
    "n_epochs = 2500 # number of iteration\n",
    "\n",
    "# create placeholders for X and Y\n",
    "X = tf.placeholder(tf.float32,[None,784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# create variable for W and b\n",
    "w = tf.Variable(tf.truncated_normal(shape = [784,10], stddev = 0.01), name = 'w')\n",
    "b = tf.Variable(tf.zeros([1,10]),name = 'b')\n",
    "\n",
    "logits = tf.matmul(X,w)+b\n",
    "normalized_logits = tf.nn.softmax(logits)\n",
    "\n",
    "# cross entropy loss\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels = Y, logits = logits))\n",
    "\n",
    "# mean_square loss\n",
    "mean_square_loss = tf.reduce_mean(tf.square(Y - normalized_logits))\n",
    "\n",
    "loss = cross_entropy\n",
    "\n",
    "#Gradient descent optimizer\n",
    "opt = tf.train.GradientDescentOptimizer(learning_rate= lr).minimize(loss)\n",
    "\n",
    "cp = tf.equal(tf.argmax(logits, axis =1), tf.argmax(Y,axis = 1))\n",
    "acc = tf.reduce_mean(tf.cast(cp, tf.float32))\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    batch = MNIST.train.next_batch(batch_size)\n",
    "    sess.run(opt, feed_dict={X:batch[0], Y:batch[1]})\n",
    "    if(i%500 == 0):\n",
    "        l = loss.eval(feed_dict={X:batch[0],Y:batch[1]})\n",
    "        print(\"loss: {}\".format(l))\n",
    "\n",
    "a = acc.eval(feed_dict={X: MNIST.test.images, Y: MNIST.test.labels})\n",
    "print(\"test acc: {}\".format(a))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABcCAYAAAB+6068AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28443552e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted 4, ground truth was 4\n",
      "predicted 1, ground truth was 1\n",
      "predicted 0, ground truth was 0\n",
      "predicted 5, ground truth was 3\n",
      "predicted 6, ground truth was 6\n"
     ]
    }
   ],
   "source": [
    "def plot_images(images):\n",
    "    for i in range(images.shape[0]):\n",
    "        plt.subplot(1, 5, i + 1) # Plotting 1 row of NUM_FIGURES.\n",
    "        plt.axis('off')\n",
    "        plt.imshow(images[i].reshape((28,28)), cmap = plt.cm.gray_r)\n",
    "    plt.show()\n",
    "    \n",
    "# TODO: Take some random images from the MNIST dataset, run a prediction, and display the prediction and the actual label.\n",
    "\n",
    "NUM_IMAGES = 5\n",
    "rand_image_idx = np.random.randint(0, MNIST.test.images.shape[1], NUM_IMAGES)\n",
    "images, labels = [MNIST.test.images[i] for i in rand_image_idx], [MNIST.test.labels[i] for i in rand_image_idx]\n",
    "images, labels = np.array(images), np.array(labels)\n",
    "plot_images(images)\n",
    "for i in range(images.shape[0]):\n",
    "    prediction = sess.run(logits, feed_dict = {X: images[i].reshape((1, images[i].shape[0])), Y: labels[i].reshape((1, labels[i].shape[0]))})\n",
    "    predicted_label = np.argmax(prediction)\n",
    "    actual_label = np.argmax(labels[i])\n",
    "    print(\"predicted {}, ground truth was {}\".format(predicted_label, actual_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
