{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot = True) # reads in the MNIST dataset\n",
    "\n",
    "# a function that shows examples from the datasets. If num is specified, then only pictures with that labels will be used\n",
    "def show_pics(mnist, num=None):\n",
    "    to_show = list(range(10)) if not num else [num]*10\n",
    "    for i in range(100):\n",
    "        batch = mnist.train.next_batch(1)\n",
    "        pic,label = batch[0],batch[1]\n",
    "        if np.argmax(label) in to_show:\n",
    "            pic = pic.reshape((28,28))\n",
    "            plt.title(\"Label: {}\".format(np.argmax(label)))\n",
    "            plt.imshow(pic,cmap='binary')\n",
    "            plt.show()\n",
    "            to_show.remove(np.argmax(label))\n",
    "            \n",
    "#show_pics(mnist,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.1))\n",
    "\n",
    "def bias_variable(shape):\n",
    "    return tf.Variable(tf.constant(0.1, shape = shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "learning_rate = 0.1\n",
    "hidden_layer_neurons = 50\n",
    "num_iterations = 5000\n",
    "\n",
    "# placeholder variables\n",
    "x = tf.placeholder(tf.float32, shape = [None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape = [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights and biases for first hidden layer\n",
    "W_1, b_1 = weight_variable([784, hidden_layer_neurons]), bias_variable([hidden_layer_neurons])\n",
    "\n",
    "# compute activatios of the hidden layer\n",
    "h_1 = tf.nn.relu(tf.matmul(x, W_1)+b_1)\n",
    "\n",
    "W_2_hidden = weight_variable([hidden_layer_neurons, 30])\n",
    "b_2_hiddent = bias_variable([30])\n",
    "h_2 = tf.nn.relu(tf.matmul(h_1, W_2_hidden) + b_2_hiddent)\n",
    "\n",
    "# create weights and biases for output layer\n",
    "W_2, b_2 = weight_variable([30,10]), bias_variable([10])\n",
    "\n",
    "#compare the output layer\n",
    "y = tf.matmul(h_2,W_2)+b_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define loss function as cross entropy loss \n",
    "cross_entropy_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels = y_, logits = y))\n",
    "\n",
    "# create an optimizer to minimize out cross entropy loss\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy_loss)\n",
    "\n",
    "# function that allow us to gauge accuracy of our model\n",
    "correct_predictions = tf.equal(tf.argmax(y,1), tf.argmax(y_,1)) # creates a vector were each elemet is true or false, denoting whether out prediction was right\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, accuracy: 0.05999999865889549, loss: 2.2969770431518555\n",
      "Epoch: 100, accuracy: 0.75, loss: 0.8947811722755432\n",
      "Epoch: 200, accuracy: 0.8399999737739563, loss: 0.4849635064601898\n",
      "Epoch: 300, accuracy: 0.949999988079071, loss: 0.23669134080410004\n",
      "Epoch: 400, accuracy: 0.8999999761581421, loss: 0.3496873378753662\n",
      "Epoch: 500, accuracy: 0.9200000166893005, loss: 0.21464763581752777\n",
      "Epoch: 600, accuracy: 0.9300000071525574, loss: 0.2453296035528183\n",
      "Epoch: 700, accuracy: 0.8999999761581421, loss: 0.3109923303127289\n",
      "Epoch: 800, accuracy: 0.9700000286102295, loss: 0.2520397901535034\n",
      "Epoch: 900, accuracy: 0.9399999976158142, loss: 0.27914345264434814\n",
      "Epoch: 1000, accuracy: 0.949999988079071, loss: 0.17681542038917542\n",
      "Epoch: 1100, accuracy: 0.9599999785423279, loss: 0.19225911796092987\n",
      "Epoch: 1200, accuracy: 0.949999988079071, loss: 0.1807815134525299\n",
      "Epoch: 1300, accuracy: 0.949999988079071, loss: 0.1292862445116043\n",
      "Epoch: 1400, accuracy: 0.9800000190734863, loss: 0.08370635658502579\n",
      "Epoch: 1500, accuracy: 0.9800000190734863, loss: 0.10742760449647903\n",
      "Epoch: 1600, accuracy: 0.9900000095367432, loss: 0.08280011266469955\n",
      "Epoch: 1700, accuracy: 0.9700000286102295, loss: 0.14869454503059387\n",
      "Epoch: 1800, accuracy: 0.9300000071525574, loss: 0.26243826746940613\n",
      "Epoch: 1900, accuracy: 0.9599999785423279, loss: 0.11315469443798065\n",
      "Epoch: 2000, accuracy: 0.9700000286102295, loss: 0.12369874864816666\n",
      "Epoch: 2100, accuracy: 0.949999988079071, loss: 0.2329346090555191\n",
      "Epoch: 2200, accuracy: 0.9900000095367432, loss: 0.06610780209302902\n",
      "Epoch: 2300, accuracy: 0.9599999785423279, loss: 0.11414610594511032\n",
      "Epoch: 2400, accuracy: 0.9800000190734863, loss: 0.08038145303726196\n",
      "Epoch: 2500, accuracy: 0.9800000190734863, loss: 0.06355896592140198\n",
      "Epoch: 2600, accuracy: 0.9800000190734863, loss: 0.12083708494901657\n",
      "Epoch: 2700, accuracy: 0.9800000190734863, loss: 0.08578284084796906\n",
      "Epoch: 2800, accuracy: 0.9900000095367432, loss: 0.06909184157848358\n",
      "Epoch: 2900, accuracy: 0.9900000095367432, loss: 0.07477396726608276\n",
      "Epoch: 3000, accuracy: 0.949999988079071, loss: 0.16475117206573486\n",
      "Epoch: 3100, accuracy: 0.9700000286102295, loss: 0.12179320305585861\n",
      "Epoch: 3200, accuracy: 1.0, loss: 0.049459561705589294\n",
      "Epoch: 3300, accuracy: 0.9800000190734863, loss: 0.07107183337211609\n",
      "Epoch: 3400, accuracy: 0.9800000190734863, loss: 0.0580919124186039\n",
      "Epoch: 3500, accuracy: 0.9800000190734863, loss: 0.06880947947502136\n",
      "Epoch: 3600, accuracy: 0.9700000286102295, loss: 0.07898372411727905\n",
      "Epoch: 3700, accuracy: 0.9800000190734863, loss: 0.07520940154790878\n",
      "Epoch: 3800, accuracy: 0.9900000095367432, loss: 0.06355094909667969\n",
      "Epoch: 3900, accuracy: 0.9900000095367432, loss: 0.10249246656894684\n",
      "Epoch: 4000, accuracy: 0.9900000095367432, loss: 0.0350036658346653\n",
      "Epoch: 4100, accuracy: 0.9900000095367432, loss: 0.05302252620458603\n",
      "Epoch: 4200, accuracy: 1.0, loss: 0.026741737499833107\n",
      "Epoch: 4300, accuracy: 0.9900000095367432, loss: 0.054590824991464615\n",
      "Epoch: 4400, accuracy: 0.9900000095367432, loss: 0.04815801978111267\n",
      "Epoch: 4500, accuracy: 1.0, loss: 0.02255854196846485\n",
      "Epoch: 4600, accuracy: 0.9700000286102295, loss: 0.08384746313095093\n",
      "Epoch: 4700, accuracy: 0.9900000095367432, loss: 0.03840314969420433\n",
      "Epoch: 4800, accuracy: 1.0, loss: 0.03859443590044975\n",
      "Epoch: 4900, accuracy: 0.9800000190734863, loss: 0.055388182401657104\n",
      "testing accuracy: 0.967199981212616\n"
     ]
    }
   ],
   "source": [
    "# session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(num_iterations):\n",
    "        # get a sample of the dataset and run the optimizer, which calculates a forward paass and then runs the backpropagation algorithm to improve the weights\n",
    "        batch = mnist.train.next_batch(100)\n",
    "        optimizer.run(feed_dict={x:batch[0], y_:batch[1]})\n",
    "        #every 100 iterations, print out the accuracy\n",
    "        if i % 100 == 0:\n",
    "            acc = accuracy.eval(feed_dict={x:batch[0], y_:batch[1]})\n",
    "            loss = cross_entropy_loss.eval(feed_dict={x:batch[0], y_:batch[1]})\n",
    "            print (\"Epoch: {}, accuracy: {}, loss: {}\".format(i, acc,loss))\n",
    "            \n",
    "    acc = accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "    print (\"testing accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
